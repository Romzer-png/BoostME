{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbec92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2892f9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kwind\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ce48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r√©cup√©ration api cl√©\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edbdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 13940 entries, 0 to 13939\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   index         13940 non-null  int64\n",
      " 1   video_id      13940 non-null  str  \n",
      " 2   title         13940 non-null  str  \n",
      " 3   description   9279 non-null   str  \n",
      " 4   channel       13940 non-null  str  \n",
      " 5   published_at  13940 non-null  str  \n",
      " 6   duration      13924 non-null  str  \n",
      " 7   views         13940 non-null  int64\n",
      " 8   likes         13940 non-null  int64\n",
      " 9   comments      13940 non-null  int64\n",
      " 10  channel_id    13940 non-null  str  \n",
      " 11  category_id   13940 non-null  int64\n",
      " 12  language      13794 non-null  str  \n",
      "dtypes: int64(5), str(8)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "# r√©cup√©rer tous les fichiers du dossier videos et d√©dupliquer les lignes\n",
    "files = glob.glob(\"CSV_Categories/*.csv\")\n",
    "\n",
    "df = []\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f)\n",
    "    df.append(csv)\n",
    "df = pd.concat(df,ignore_index=True)\n",
    "df = df.sort_values(by=['video_id', 'views'])\n",
    "df.drop_duplicates(subset=['video_id'], keep=\"last\", inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85bdd73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "Index: 4113 entries, 0 to 8038\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   channel_id  4113 non-null   str  \n",
      " 1   views       4113 non-null   int64\n",
      "dtypes: int64(1), str(1)\n",
      "memory usage: 96.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_top_chaines = df.groupby('channel_id')['views'].sum().reset_index()\n",
    "df_top_chaines = df_top_chaines[df_top_chaines['views'] > 10000]\n",
    "df_top_chaines.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdcbba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 4110 entries, 0 to 4109\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   id                4110 non-null   str   \n",
      " 1   title             4110 non-null   str   \n",
      " 2   description       4110 non-null   str   \n",
      " 3   country           3129 non-null   str   \n",
      " 4   views             4110 non-null   int64 \n",
      " 5   subscribers       4110 non-null   int64 \n",
      " 6   nb_videos         4110 non-null   int64 \n",
      " 7   uploads_playlist  4110 non-null   str   \n",
      " 8   topics            4110 non-null   object\n",
      "dtypes: int64(3), object(1), str(5)\n",
      "memory usage: 289.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# R√©cup√©ration des infos des chaines\n",
    "all_channel_data = []\n",
    "\n",
    "# On boucle sur le DataFrame par paquets de 50 IDs\n",
    "for i in range(0, len(df_top_chaines), 50):\n",
    "    batch_ids = df_top_chaines['channel_id'].iloc[i:i+50].tolist()\n",
    "    ids_string = \",\".join(batch_ids) \n",
    "    \n",
    "    params = {\n",
    "        \"part\": \"snippet,contentDetails,statistics,topicDetails,status\",\n",
    "        \"id\": ids_string,\n",
    "        \"key\": API_KEY\n",
    "    }\n",
    "\n",
    "    r = requests.get(f\"https://www.googleapis.com/youtube/v3/channels\", params=params)\n",
    "    data = r.json()\n",
    "\n",
    "    if \"items\" in data:\n",
    "        for item in data[\"items\"]:\n",
    "            snippet = item.get(\"snippet\", {})\n",
    "            statistics = item.get(\"statistics\", {})\n",
    "            contentDetails = item.get(\"contentDetails\", {})\n",
    "            topicDetails = item.get(\"topicDetails\", {})\n",
    "            status = item.get(\"status\", {})\n",
    "\n",
    "            channel_info = {\n",
    "                \"id\": item.get(\"id\"),\n",
    "                \"title\": snippet.get(\"title\"),\n",
    "                \"description\": snippet.get(\"description\"),\n",
    "                \"country\": snippet.get(\"country\"),\n",
    "                \"views\": int(statistics.get(\"viewCount\", 0)),\n",
    "                \"subscribers\": int(statistics.get(\"subscriberCount\", 0)),\n",
    "                \"nb_videos\": int(statistics.get(\"videoCount\", 0)),\n",
    "                \"uploads_playlist\": contentDetails.get(\"relatedPlaylists\", {}).get(\"uploads\", \"\"),\n",
    "                \"topics\": topicDetails.get(\"topicCategories\", []) # Plus lisible que topicIds\n",
    "            }\n",
    "            all_channel_data.append(channel_info)\n",
    "\n",
    "# Cr√©ation du DataFrame final\n",
    "df_channels = pd.DataFrame(all_channel_data)\n",
    "df_channels.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8204af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2092 entries, 0 to 2091\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   index             2092 non-null   int64 \n",
      " 1   id                2092 non-null   str   \n",
      " 2   title             2092 non-null   str   \n",
      " 3   description       2092 non-null   str   \n",
      " 4   country           2092 non-null   str   \n",
      " 5   views             2092 non-null   int64 \n",
      " 6   subscribers       2092 non-null   int64 \n",
      " 7   nb_videos         2092 non-null   int64 \n",
      " 8   uploads_playlist  2092 non-null   str   \n",
      " 9   topics            2092 non-null   object\n",
      "dtypes: int64(4), object(1), str(5)\n",
      "memory usage: 163.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# ne garder que les chaines fr, us, gb, ca, de\n",
    "df_channels =  df_channels[(df_channels['country']==\"FR\")|(df_channels['country']==\"US\")|(df_channels['country']==\"GB\")|(df_channels['country']==\"CA\")|(df_channels['country']==\"DE\"\n",
    "\"\")].copy()\n",
    "df_channels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6947e127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtags\n",
       "#shorts            6\n",
       "#1                 4\n",
       "#humour            4\n",
       "#roblox            3\n",
       "#organisation      3\n",
       "                  ..\n",
       "#60hits            1\n",
       "#heavyrock         1\n",
       "#classicrock       1\n",
       "#heavyrockmusic    1\n",
       "#livestream        1\n",
       "Name: count, Length: 507, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COLONNE HASHTAGS\n",
    "\n",
    "# extraction des hashtags des colonnes title et description\n",
    "text_title_description = df_channels['title'].fillna('') + \" \" + df_channels['description'].fillna('')\n",
    "df_channels['hashtags'] = text_title_description.apply(lambda x: list(set(re.findall(r\"#\\w+\", x))) or None)\n",
    "\n",
    "# exploser la colonne hashtag pour compter les occurences\n",
    "df_exploded = df_channels.explode('hashtags').copy()\n",
    "df_exploded = df_exploded.dropna(subset=['hashtags'])\n",
    "\n",
    "df_exploded['hashtags'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c46b59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLONNE TOPICS\n",
    "\n",
    "def extract_topic_name(topic_list):\n",
    "    # Si la valeur est None ou n'est pas une liste/iterable\n",
    "    if not isinstance(topic_list, list):\n",
    "        return \"\"\n",
    "    \n",
    "    # Nettoyage de chaque URL dans la liste\n",
    "    clean_list = [url.split('/')[-1].replace('_', ' ') for url in topic_list]\n",
    "    return \", \".join(clean_list)\n",
    "\n",
    "df_channels['topics'] = df_channels['topics'].apply(extract_topic_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1c299da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLONNE KEYWORDS (uniquement pour chaines FR)\n",
    "\n",
    "def clean_stem(str):\n",
    "  items_to_remove= set(stopwords.words(\"french\"))\n",
    "\n",
    "  #tokenisation\n",
    "  texte_tokens =  nltk.word_tokenize(str)\n",
    "\n",
    "  tokens_clean = []\n",
    "\n",
    "  # suppression stopwords\n",
    "  for word in texte_tokens :\n",
    "    word =  word.lower()\n",
    "    #version bis : on ne supprime pas la ponctuation\n",
    "    if word not in items_to_remove:\n",
    "      tokens_clean.append(word)\n",
    "\n",
    "\n",
    "  # stemming\n",
    "  stem_en = SnowballStemmer(\"french\")\n",
    "  texte_clean_stem  = [stem_en.stem(word) for word in tokens_clean]\n",
    "  return(' '.join(texte_clean_stem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93f7aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>views</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>nb_videos</th>\n",
       "      <th>uploads_playlist</th>\n",
       "      <th>topics</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>UC-1FhqxA7zOPVG4fl2qBs_A</td>\n",
       "      <td>Roxas V6</td>\n",
       "      <td>Yo les amis c'est Roxas ^^ \\nPassionn√© de jeux...</td>\n",
       "      <td>FR</td>\n",
       "      <td>3599518</td>\n",
       "      <td>19700</td>\n",
       "      <td>489</td>\n",
       "      <td>UU-1FhqxA7zOPVG4fl2qBs_A</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>yo amis c'est rox ^^ passion jeux vid√©os , j'a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>UC-6XX8GoB0LgINUjnuXWZrQ</td>\n",
       "      <td>ZigTik</td>\n",
       "      <td>Bienvenue sur notre cha√Æne de d√©fis et de dive...</td>\n",
       "      <td>FR</td>\n",
       "      <td>7782549</td>\n",
       "      <td>70900</td>\n",
       "      <td>69</td>\n",
       "      <td>UU-6XX8GoB0LgINUjnuXWZrQ</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>bienvenu cha√Æn def divert captiv ! üéâ plong uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>UC-4xdm_HWFZqaoZVbJ72o0w</td>\n",
       "      <td>Redouane Bougheraba TV</td>\n",
       "      <td>Allez Paf... tu trouveras ici sur ma cha√Æne Yo...</td>\n",
       "      <td>FR</td>\n",
       "      <td>203685091</td>\n",
       "      <td>558000</td>\n",
       "      <td>440</td>\n",
       "      <td>UU-4xdm_HWFZqaoZVbJ72o0w</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>allez paf ... trouv ici cha√Æn youtub meilleur ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>UC-3UNIRUAEnjQSJVTz2Q2WA</td>\n",
       "      <td>MangaMotionStudio</td>\n",
       "      <td>üé¨ MangaMotionStudio&nbsp;&nbsp;l‚Äôunivers des AMV √©motion...</td>\n",
       "      <td>FR</td>\n",
       "      <td>335491</td>\n",
       "      <td>3320</td>\n",
       "      <td>45</td>\n",
       "      <td>UU-3UNIRUAEnjQSJVTz2Q2WA</td>\n",
       "      <td></td>\n",
       "      <td>[#AnimeEdit, #AnimeVibes, #AMV, #EpicAMV, #Emo...</td>\n",
       "      <td>üé¨ mangamotionstudio ‚Äô univer amv √©motionnel √©p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>UC-KkVdOP86k1SDAWzFfw8nA</td>\n",
       "      <td>DEMONEXION</td>\n",
       "      <td>WESH LES FR√âROTS c'est .. TONTON DEMONEXION ! ...</td>\n",
       "      <td>FR</td>\n",
       "      <td>288202334</td>\n",
       "      <td>718000</td>\n",
       "      <td>492</td>\n",
       "      <td>UU-KkVdOP86k1SDAWzFfw8nA</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>wesh fr√©rot c'est .. tonton demonexion ! bon h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        id                   title  \\\n",
       "2      7  UC-1FhqxA7zOPVG4fl2qBs_A                Roxas V6   \n",
       "3      8  UC-6XX8GoB0LgINUjnuXWZrQ                  ZigTik   \n",
       "5     10  UC-4xdm_HWFZqaoZVbJ72o0w  Redouane Bougheraba TV   \n",
       "6     11  UC-3UNIRUAEnjQSJVTz2Q2WA       MangaMotionStudio   \n",
       "7     12  UC-KkVdOP86k1SDAWzFfw8nA              DEMONEXION   \n",
       "\n",
       "                                         description country      views  \\\n",
       "2  Yo les amis c'est Roxas ^^ \\nPassionn√© de jeux...      FR    3599518   \n",
       "3  Bienvenue sur notre cha√Æne de d√©fis et de dive...      FR    7782549   \n",
       "5  Allez Paf... tu trouveras ici sur ma cha√Æne Yo...      FR  203685091   \n",
       "6  üé¨ MangaMotionStudio  l‚Äôunivers des AMV √©motion...      FR     335491   \n",
       "7  WESH LES FR√âROTS c'est .. TONTON DEMONEXION ! ...      FR  288202334   \n",
       "\n",
       "   subscribers  nb_videos          uploads_playlist topics  \\\n",
       "2        19700        489  UU-1FhqxA7zOPVG4fl2qBs_A          \n",
       "3        70900         69  UU-6XX8GoB0LgINUjnuXWZrQ          \n",
       "5       558000        440  UU-4xdm_HWFZqaoZVbJ72o0w          \n",
       "6         3320         45  UU-3UNIRUAEnjQSJVTz2Q2WA          \n",
       "7       718000        492  UU-KkVdOP86k1SDAWzFfw8nA          \n",
       "\n",
       "                                            hashtags  \\\n",
       "2                                               None   \n",
       "3                                               None   \n",
       "5                                               None   \n",
       "6  [#AnimeEdit, #AnimeVibes, #AMV, #EpicAMV, #Emo...   \n",
       "7                                               None   \n",
       "\n",
       "                                            keywords  \n",
       "2  yo amis c'est rox ^^ passion jeux vid√©os , j'a...  \n",
       "3  bienvenu cha√Æn def divert captiv ! üéâ plong uni...  \n",
       "5  allez paf ... trouv ici cha√Æn youtub meilleur ...  \n",
       "6  üé¨ mangamotionstudio ‚Äô univer amv √©motionnel √©p...  \n",
       "7  wesh fr√©rot c'est .. tonton demonexion ! bon h...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels_fr =  df_channels[df_channels['country']==\"FR\"]\n",
    "df_channels_fr.reset_index()\n",
    "df_channels_fr['keywords'] = df_channels['description'].apply(clean_stem)\n",
    "df_channels_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3350410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "      <th>views</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>nb_videos</th>\n",
       "      <th>uploads_playlist</th>\n",
       "      <th>topics</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UC-4xdm_HWFZqaoZVbJ72o0w</td>\n",
       "      <td>Redouane Bougheraba TV</td>\n",
       "      <td>Allez Paf... tu trouveras ici sur ma cha√Æne Yo...</td>\n",
       "      <td>FR</td>\n",
       "      <td>203685091</td>\n",
       "      <td>558000</td>\n",
       "      <td>440</td>\n",
       "      <td>UU-4xdm_HWFZqaoZVbJ72o0w</td>\n",
       "      <td>Film, Humour, Entertainment, Performing arts</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UC-RoMo4xRoyymgJs8Z3IvzQ</td>\n",
       "      <td>Mari Am</td>\n",
       "      <td>Enchant√©e, Mariam ü§ç\\nOn se retrouve tous les d...</td>\n",
       "      <td>FR</td>\n",
       "      <td>7440512</td>\n",
       "      <td>146000</td>\n",
       "      <td>74</td>\n",
       "      <td>UU-RoMo4xRoyymgJs8Z3IvzQ</td>\n",
       "      <td>Fashion, Lifestyle (sociology)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UC-6XX8GoB0LgINUjnuXWZrQ</td>\n",
       "      <td>ZigTik</td>\n",
       "      <td>Bienvenue sur notre cha√Æne de d√©fis et de dive...</td>\n",
       "      <td>FR</td>\n",
       "      <td>7782549</td>\n",
       "      <td>71000</td>\n",
       "      <td>69</td>\n",
       "      <td>UU-6XX8GoB0LgINUjnuXWZrQ</td>\n",
       "      <td>Entertainment, Humour, Performing arts</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UC-2sU9mpGUd1t6O2OG2paVA</td>\n",
       "      <td>Team NASDAS ü¶Ö</td>\n",
       "      <td>‚≠ï Voici la cha√Æne professionnelle de Team Nasd...</td>\n",
       "      <td>FR</td>\n",
       "      <td>233771184</td>\n",
       "      <td>113000</td>\n",
       "      <td>4113</td>\n",
       "      <td>UU-2sU9mpGUd1t6O2OG2paVA</td>\n",
       "      <td>Lifestyle (sociology), Humour, Entertainment, ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC-ITzVg0OCQx9_7mldBMgpg</td>\n",
       "      <td>Rattus</td>\n",
       "      <td>Apr√®s quatre ans enferm√© dans une BD, Rattus, ...</td>\n",
       "      <td>FR</td>\n",
       "      <td>1536411</td>\n",
       "      <td>21600</td>\n",
       "      <td>233</td>\n",
       "      <td>UU-ITzVg0OCQx9_7mldBMgpg</td>\n",
       "      <td>Lifestyle (sociology), Entertainment, Music, H...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                   title  \\\n",
       "0  UC-4xdm_HWFZqaoZVbJ72o0w  Redouane Bougheraba TV   \n",
       "1  UC-RoMo4xRoyymgJs8Z3IvzQ                 Mari Am   \n",
       "2  UC-6XX8GoB0LgINUjnuXWZrQ                  ZigTik   \n",
       "3  UC-2sU9mpGUd1t6O2OG2paVA           Team NASDAS ü¶Ö   \n",
       "4  UC-ITzVg0OCQx9_7mldBMgpg                  Rattus   \n",
       "\n",
       "                                         description country      views  \\\n",
       "0  Allez Paf... tu trouveras ici sur ma cha√Æne Yo...      FR  203685091   \n",
       "1  Enchant√©e, Mariam ü§ç\\nOn se retrouve tous les d...      FR    7440512   \n",
       "2  Bienvenue sur notre cha√Æne de d√©fis et de dive...      FR    7782549   \n",
       "3  ‚≠ï Voici la cha√Æne professionnelle de Team Nasd...      FR  233771184   \n",
       "4  Apr√®s quatre ans enferm√© dans une BD, Rattus, ...      FR    1536411   \n",
       "\n",
       "   subscribers  nb_videos          uploads_playlist  \\\n",
       "0       558000        440  UU-4xdm_HWFZqaoZVbJ72o0w   \n",
       "1       146000         74  UU-RoMo4xRoyymgJs8Z3IvzQ   \n",
       "2        71000         69  UU-6XX8GoB0LgINUjnuXWZrQ   \n",
       "3       113000       4113  UU-2sU9mpGUd1t6O2OG2paVA   \n",
       "4        21600        233  UU-ITzVg0OCQx9_7mldBMgpg   \n",
       "\n",
       "                                              topics hashtags  \n",
       "0       Film, Humour, Entertainment, Performing arts     None  \n",
       "1                     Fashion, Lifestyle (sociology)     None  \n",
       "2             Entertainment, Humour, Performing arts     None  \n",
       "3  Lifestyle (sociology), Humour, Entertainment, ...     None  \n",
       "4  Lifestyle (sociology), Entertainment, Music, H...     None  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_channels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de950371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channels.to_csv(\"chaines.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boostme-env (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
